---
title: "Support Vector Machine (SVM)"
author: "Clifford Mwenda"
date: "2024-04-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



DATA PREPROCESSING

Import Data Set
```{r}
setwd("C:/Users/Latitude/Desktop/Mushroom Classification")
dataset = read.csv("mushroom.csv", na.strings = c("", " ", "NA"))
str(dataset)
```

Make Character Variables Factors
```{r}
library(dplyr)
dataset <- dataset %>%
  mutate(across(-c(cap.diameter, stem.height, stem.width), as.factor))
str(dataset)
```

Check DV Distribution
```{r}
prop.table(table(dataset$class))

#Here we want to confirm that the distribution between the two label data is not too much different. Because imbalanced datasets can lead to imbalanced accuracy.
```

Check NAs and Drop Columns with NAs
```{r}
n_nas = colSums(is.na(dataset))
(n_nas/61069) * 100
dataset = dataset %>% select(where(~ !any(is.na(.))))
str(dataset)
```

Re-Arrange Columns
```{r}
dataset = dataset[, c(2:12, 1)]
str(dataset)
```

Split Data-set into Training and Testing
```{r}
library("caTools")
set.seed(123)
split = sample.split(dataset$class, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
```

Feature Scaling
```{r}
training_set[, c(1, 6:7)] = scale(training_set[, c(1, 6:7)]) #Z Score
test_set[, c(1, 6:7)] = scale(test_set[, c(1, 6:7)])


str(training_set)
```








FITTING AND EVALUATING THE MODEL

Fitting Linear_SVM to the Training set, Predicting the Test set results, and Making the Confusion Matrix
```{r}
library(e1071)
classifier = svm(formula = training_set$class ~ .,
                 data = training_set,
                 type = 'C-classification',
                 kernel = 'linear')


y_pred = predict(classifier, newdata = test_set[-12])


cm = table(test_set[, 12], y_pred)

accuracy = (cm[1, 1] + cm[2, 2]) / (cm[1, 1] + cm[2, 2] + cm[1, 2] + cm[2, 1])
accuracy #72.37%
```

Apply K-Fold Cross-Validation (Took Very Long)
```{r}
library(caret)
library(e1071)
# in creating the folds we specify the target feature (dependent variable) and # of folds
folds = createFolds(training_set$class, k = 10)
# in cv we are going to applying a created function to our 'folds'
cv = lapply(folds, function(x) { # start of function
  # in the next two lines we will separate the Training set into it's 10 pieces
  training_fold = training_set[-x, ] # training fold =  training set minus (-) it's sub test fold
  test_fold = training_set[x, ] # here we describe the test fold individually
  # now apply (train) the classifer on the training_fold
  classifier = svm(formula = class ~ .,
                   data = training_fold,
                   type = 'C-classification',
                   kernel = 'linear')
  # next step in the loop, we calculate the predictions and cm and we equate the accuracy
  # note we are training on training_fold and testing its accuracy on the test_fold
  y_pred = predict(classifier, newdata = test_fold[-12])
  cm = table(test_fold[, 12], y_pred)
  accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
  return(accuracy)
})
#We compute the mean of the accuracies to get the ultimum accuracy
accuracy = mean(as.numeric(cv))
accuracy #72.62%
```


